import streamlit as st
import analyzer
import pandas as pd

TEXTS = {
    "page_title": {"ko": "MirrorOrg ë‹¨ê³„ë³„ MVP", "en": "MirrorOrg Stepwise MVP"},
    "main_title": {"ko": "ğŸª MirrorOrg ë‹¨ê³„ë³„ íŒ€ ë¶„ì„", "en": "ğŸª MirrorOrg Stepwise Team Analysis"},
    "main_description": {
        "ko": "â‘  íŒŒì¼ ì—…ë¡œë“œ â†’ â‘¡ ì±•í„°ë³„ ë¶„ì„ ì‹¤í–‰ â†’ â‘¢ ê²°ê³¼ í™•ì¸ì˜ ìˆœì„œë¡œ ì•ˆì „í•˜ê³  ì§ê´€ì ì¸ íŒ€ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.",
        "en": "Upload file â†’ Run each chapter â†’ View result. This safe, clear flow ensures robust team analysis."
    },
    "sidebar_header": {"ko": "ì„¤ì •", "en": "Settings"},
    "language_selector": {"ko": "ì–¸ì–´", "en": "Language"},
    "upload_header": {"ko": "1ï¸âƒ£ ì±„íŒ… ê¸°ë¡ ì—…ë¡œë“œ", "en": "1ï¸âƒ£ Upload Chat History"},
    "upload_info": {
        "ko": "íŒ€ ì±„íŒ… ê¸°ë¡ì„ .txt íŒŒì¼ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”. ì—…ë¡œë“œ ì „ê¹Œì§€ ì•„ë˜ ë‹¨ê³„ëŠ” ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.",
        "en": "Upload your team chat history as a .txt file. Steps below are disabled until upload."
    },
    "file_uploader_label": {"ko": "ë¶„ì„í•  .txt íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", "en": "Choose a .txt file to analyze."},
    "chapter_header": {"ko": "2ï¸âƒ£ ì±•í„°ë³„ ë¶„ì„ ì‹¤í–‰", "en": "2ï¸âƒ£ Run Each Analysis Chapter"},
    "chapter1_btn": {"ko": "ì±•í„° 1: ì¢…í•© ë³´ê³ ì„œ", "en": "Chapter 1: Comprehensive Report"},
    "chapter2_btn": {"ko": "ì±•í„° 2: í”¼ë¡œë„ ê³¡ì„ ", "en": "Chapter 2: Fatigue Trajectory"},
    "chapter3_btn": {"ko": "ì±•í„° 3: ê´€ê³„ ë„¤íŠ¸ì›Œí¬", "en": "Chapter 3: Relationship Network"},
    "analysis_complete": {"ko": "âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", "en": "âœ… Analysis complete!"},
    "results_header": {"ko": "3ï¸âƒ£ ê²°ê³¼ í™•ì¸", "en": "3ï¸âƒ£ View Results"},
    "fatigue_title": {"ko": "ì±•í„° 2 ê²°ê³¼: í”¼ë¡œë„ ê³¡ì„ ", "en": "Chapter 2 Result: Fatigue Trajectory"},
    "network_title": {"ko": "ì±•í„° 3 ê²°ê³¼: ê´€ê³„ ë„¤íŠ¸ì›Œí¬", "en": "Chapter 3 Result: Relationship Network"},
    "no_fatigue_data": {"ko": "í”¼ë¡œë„ ê³¡ì„  ë°ì´í„°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "en": "Fatigue trajectory data could not be visualized."},
    "no_network_data": {"ko": "ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë¥¼ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "en": "Network data could not be visualized."},
    "report_title": {"ko": "ì±•í„° 1 ê²°ê³¼: ì¢…í•© ë³´ê³ ì„œ", "en": "Chapter 1 Result: Comprehensive Report"},
    "raw_llm": {"ko": "LLM ì›ë³¸ ì‘ë‹µ(raw)", "en": "LLM Raw Response"},
}

# 1. Page config & ì–¸ì–´ ì„¤ì •
st.set_page_config(page_title=TEXTS["page_title"]["en"], page_icon="ğŸ¤–", layout="wide")
if 'lang' not in st.session_state:
    st.session_state.lang = 'ko'

# 2. Sidebar (Language Switch)
with st.sidebar:
    st.header(TEXTS["sidebar_header"][st.session_state.lang])
    lang_choice = st.selectbox(
        label=f'{TEXTS["language_selector"]["en"]} / {TEXTS["language_selector"]["ko"]}',
        options=['í•œêµ­ì–´', 'English'],
        index=0 if st.session_state.lang == 'ko' else 1
    )
    st.session_state.lang = 'ko' if lang_choice == 'í•œêµ­ì–´' else 'en'
lang = st.session_state.lang

# 3. Main UI
st.title(TEXTS["main_title"][lang])
st.markdown(TEXTS["main_description"][lang])

st.header(TEXTS["upload_header"][lang])
st.info(TEXTS["upload_info"][lang])
uploaded_file = st.file_uploader(TEXTS["file_uploader_label"][lang], type="txt")

if not uploaded_file:
    st.stop()

file_content = uploaded_file.getvalue().decode("utf-8")
st.success(f"'{uploaded_file.name}' íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

# 4. ì±•í„°ë³„ ë¶„ì„ ì‹¤í–‰
st.header(TEXTS["chapter_header"][lang])
col1, col2, col3 = st.columns(3)

# ì±•í„°1: ì¢…í•© ë³´ê³ ì„œ
with col1:
    if st.button(TEXTS["chapter1_btn"][lang], use_container_width=True):
        with st.spinner("ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
            st.session_state.report = analyzer.generate_report(file_content, lang=lang)
        st.toast(TEXTS["analysis_complete"][lang], icon="âœ…")

# ì±•í„°2: í”¼ë¡œë„ ê³¡ì„ 
with col2:
    if st.button(TEXTS["chapter2_btn"][lang], use_container_width=True):
        with st.spinner("í”¼ë¡œë„ ë¶„ì„ ì¤‘..."):
            st.session_state.fatigue_data = analyzer.analyze_fatigue_json(file_content, lang=lang)
        st.toast(TEXTS["analysis_complete"][lang], icon="âœ…")

# ì±•í„°3: ê´€ê³„ ë„¤íŠ¸ì›Œí¬
with col3:
    if st.button(TEXTS["chapter3_btn"][lang], use_container_width=True):
        with st.spinner("ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì¤‘..."):
            st.session_state.network_data = analyzer.analyze_network_json(file_content, lang=lang)
        st.toast(TEXTS["analysis_complete"][lang], icon="âœ…")

# 5. ê²°ê³¼ í™•ì¸(ì±•í„°ë³„ ë°ì´í„°ê°€ ìƒì„±ëœ í›„ì—ë§Œ!)
st.header(TEXTS["results_header"][lang])

if st.session_state.get('report'):
    st.subheader(TEXTS["report_title"][lang])
    st.markdown(st.session_state.report, unsafe_allow_html=True)
    st.divider()

if st.session_state.get('fatigue_data'):
    st.subheader(TEXTS["fatigue_title"][lang])
    fatigue_data = st.session_state.get('fatigue_data')
    if fatigue_data and isinstance(fatigue_data, list):
        try:
            lines = []
            for item in fatigue_data:
                if "name" not in item or "fatigue_timeline" not in item:
                    st.error(f"í•„ë“œ ëˆ„ë½: {item}")
                    continue
                for d in item["fatigue_timeline"]:
                    if "date" not in d or "score" not in d:
                        st.error(f"ë‚ ì§œ/ì ìˆ˜ ëˆ„ë½: {d}")
                        continue
                    lines.append({"name": item["name"], "date": d["date"], "score": d["score"]})
            if not lines:
                st.warning("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŒ")
            else:
                df = pd.DataFrame(lines)
                chart_data = df.pivot(index="date", columns="name", values="score")
                st.line_chart(chart_data)
        except Exception as e:
            st.error(f"{TEXTS['no_fatigue_data'][lang]}: {e}")
    elif fatigue_data and "raw_response" in fatigue_data:
        st.warning(TEXTS["raw_llm"][lang] + ":")
        st.code(fatigue_data["raw_response"])
        st.info(TEXTS["no_fatigue_data"][lang])
    else:
        st.info(TEXTS["no_fatigue_data"][lang])

if st.session_state.get('network_data'):
    st.subheader(TEXTS["network_title"][lang])
    network_data = st.session_state.get('network_data')
    if network_data and isinstance(network_data, list):
        try:
            import networkx as nx
            import matplotlib.pyplot as plt
            G = nx.Graph()
            for link in network_data:
                if "source" not in link or "target" not in link:
                    st.error(f"í•„ë“œ ëˆ„ë½: {link}")
                    continue
                G.add_edge(link["source"], link["target"], weight=link.get("strength", 1), type=link.get("type", ""))
            fig, ax = plt.subplots()
            pos = nx.spring_layout(G)
            nx.draw(G, pos, with_labels=True, ax=ax, node_color='lightblue', edge_color='gray')
            st.pyplot(fig)
        except Exception as e:
            st.error(f"{TEXTS['no_network_data'][lang]}: {e}")
    elif network_data and "raw_response" in network_data:
        st.warning(TEXTS["raw_llm"][lang] + ":")
        st.code(network_data["raw_response"])
        st.info(TEXTS["no_network_data"][lang])
    else:
        st.info(TEXTS["no_network_data"][lang])
