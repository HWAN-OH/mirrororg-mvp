{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HWAN-OH/mirrororg-mvp/blob/main/app.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from pyvis.network import Network\n",
        "import streamlit.components.v1 as components\n",
        "from datetime import datetime\n",
        "\n",
        "# --- [Delta] Centralized Text Management for Multilingual Support ---\n",
        "TEXTS = {\n",
        "    # General UI\n",
        "    \"page_title\": {\"ko\": \"MirrorOrg MVP v3\", \"en\": \"MirrorOrg MVP v3\"},\n",
        "    \"main_title\": {\"ko\": \"ğŸª MirrorOrg MVP: ì¢…í•© íŒ€ ë¶„ì„\", \"en\": \"ğŸª MirrorOrg MVP: Comprehensive Team Analysis\"},\n",
        "    \"main_description\": {\n",
        "        \"ko\": \"'ë¯¸ëŸ¬ì˜¤ì•Œì§€ íŒ€ ë¶„ì„ ì‚¬ë¡€'ì— ê¸°ë°˜í•œ ë‹¤ì°¨ì› í˜‘ì—… ì§„ë‹¨ ë„êµ¬ì…ë‹ˆë‹¤.\\nì¹´ì¹´ì˜¤í†¡ ì±„íŒ… ê¸°ë¡ì„ ì—…ë¡œë“œí•˜ì—¬ **íŒ€ í”„ë¡œí•„, í”¼ë¡œë„ ë³€í™”, ê´€ê³„ ë„¤íŠ¸ì›Œí¬**ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì§„ë‹¨í•©ë‹ˆë‹¤.\",\n",
        "        \"en\": \"A multi-dimensional collaboration diagnostic tool based on the 'MirrorOrg Team Analysis Case Study'.\\nUpload your KakaoTalk chat history to diagnose **Team Profile, Fatigue Trajectory, and Relationship Network**.\"\n",
        "    },\n",
        "    # Sidebar\n",
        "    \"sidebar_header\": {\"ko\": \"ì„¤ì •\", \"en\": \"Settings\"},\n",
        "    \"language_selector\": {\"ko\": \"ì–¸ì–´\", \"en\": \"Language\"},\n",
        "    \"api_key_loaded\": {\"ko\": \"API í‚¤ê°€ ì•ˆì „í•˜ê²Œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\", \"en\": \"API key loaded securely.\"},\n",
        "    \"local_env_warning\": {\"ko\": \"âš ï¸ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.\", \"en\": \"âš ï¸ Running in a local environment.\"},\n",
        "    \"api_key_input\": {\"ko\": \"Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:\", \"en\": \"Enter your Gemini API Key:\"},\n",
        "    \"api_key_success\": {\"ko\": \"API í‚¤ ì„¤ì • ì™„ë£Œ!\", \"en\": \"API key configured successfully!\"},\n",
        "    \"api_key_failure\": {\"ko\": \"API í‚¤ ì„¤ì • ì‹¤íŒ¨\", \"en\": \"API key configuration failed\"},\n",
        "    \"api_key_info\": {\n",
        "        \"ko\": \"ì‹œì‘í•˜ë ¤ë©´ Gemini API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. [API í‚¤ ë°œê¸‰ë°›ê¸°](https://aistudio.google.com/app/apikey)\",\n",
        "        \"en\": \"Please enter your Gemini API key to start. [Get an API Key](https://aistudio.google.com/app/apikey)\"\n",
        "    },\n",
        "    # Main Content\n",
        "    \"upload_header\": {\"ko\": \"1. ì±„íŒ… ê¸°ë¡ ì—…ë¡œë“œ\", \"en\": \"1. Upload Chat History\"},\n",
        "    \"upload_info\": {\n",
        "        \"ko\": \"ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” 'ë‚´ë³´ë‚´ê¸°' > 'í…ìŠ¤íŠ¸ íŒŒì¼ë§Œ' ì €ì¥ í›„ ì—…ë¡œë“œí•˜ì„¸ìš”. ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ì´ë¦„ ë“± ë¯¼ê°ì •ë³´ë¥¼ ìˆ˜ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\",\n",
        "        \"en\": \"Export your KakaoTalk chat ('Export Text Only') and upload the .txt file. For privacy, we recommend anonymizing names and sensitive information before uploading.\"\n",
        "    },\n",
        "    \"file_uploader_label\": {\"ko\": \"ë¶„ì„í•  .txt íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.\", \"en\": \"Choose a .txt file to analyze.\"},\n",
        "    \"parsing_success\": {\"ko\": \"íŒŒì¼ íŒŒì‹± ì„±ê³µ! {count}ê°œì˜ ë©”ì‹œì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\", \"en\": \"File parsed successfully! Found {count} messages.\"},\n",
        "    \"parsing_error\": {\"ko\": \"ì¹´ì¹´ì˜¤í†¡ íŒŒì¼ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\", \"en\": \"Could not recognize the KakaoTalk file format. Please check the file.\"},\n",
        "    \"analysis_button\": {\"ko\": \"ì¢…í•© ë¶„ì„ ì‹œì‘í•˜ê¸° ğŸš€\", \"en\": \"Start Comprehensive Analysis ğŸš€\"},\n",
        "    \"spinner_profile\": {\"ko\": \"1/3: íŒ€ í”„ë¡œí•„ ë¶„ì„ ì¤‘...\", \"en\": \"1/3: Analyzing Team Profile...\"},\n",
        "    \"spinner_timeline\": {\"ko\": \"2/3: í”¼ë¡œë„ íƒ€ì„ë¼ì¸ ë¶„ì„ ì¤‘...\", \"en\": \"2/3: Analyzing Fatigue Timeline...\"},\n",
        "    \"spinner_network\": {\"ko\": \"3/3: ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì¤‘...\", \"en\": \"3/3: Analyzing Relationship Network...\"},\n",
        "    \"analysis_complete\": {\"ko\": \"âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.\", \"en\": \"âœ… Analysis complete! Check the results in the tabs below.\"},\n",
        "    \"file_process_error\": {\"ko\": \"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ\", \"en\": \"Error processing file\"},\n",
        "    # Results\n",
        "    \"results_header\": {\"ko\": \"2. ì§„ë‹¨ ê²°ê³¼\", \"en\": \"2. Diagnostic Results\"},\n",
        "    \"tab_profile\": {\"ko\": \"**íŒ€ í”„ë¡œí•„ (ì§„ë‹¨)**\", \"en\": \"**Team Profile (Diagnosis)**\"},\n",
        "    \"tab_fatigue\": {\"ko\": \"**í”¼ë¡œë„ ë³€í™” (ì˜ˆì¸¡)**\", \"en\": \"**Fatigue Trajectory (Prediction)**\"},\n",
        "    \"tab_network\": {\"ko\": \"**ê´€ê³„ ë„¤íŠ¸ì›Œí¬ (ì˜ˆì¸¡)**\", \"en\": \"**Relationship Network (Prediction)**\"},\n",
        "    \"profile_subheader\": {\"ko\": \"ì •ì²´ì„± ê³„ìˆ˜ ë§µ (Identity Coefficient Map)\", \"en\": \"Identity Coefficient Map\"},\n",
        "    \"profile_info\": {\"ko\": \"íŒ€ì›ë“¤ì˜ ì„±í–¥ê³¼ ì—­í• ì„ íŒŒì•…í•˜ì—¬ íŒ€ì˜ ì „ì²´ì ì¸ êµ¬ì„±ì„ ì§„ë‹¨í•©ë‹ˆë‹¤.\", \"en\": \"Diagnoses the overall team composition by identifying member traits and roles.\"},\n",
        "    \"profile_error\": {\"ko\": \"í”„ë¡œí•„ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\", \"en\": \"Could not display profile data\"},\n",
        "    \"profile_warning\": {\"ko\": \"íŒ€ í”„ë¡œí•„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\", \"en\": \"No team profile data available.\"},\n",
        "    \"fatigue_subheader\": {\"ko\": \"í”¼ë¡œë„ ì‹œê³„ì—´ ê·¸ë˜í”„ (Fatigue Timeline)\", \"en\": \"Fatigue Timeline Graph\"},\n",
        "    \"fatigue_info\": {\"ko\": \"ì‹œê°„ì— ë”°ë¥¸ íŒ€ì›ë“¤ì˜ ê°ì •ì , ì—…ë¬´ì  ì†Œì§„ ìƒíƒœì˜ ë³€í™”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\", \"en\": \"Predicts the changes in team members' emotional and professional burnout over time.\"},\n",
        "    \"fatigue_error\": {\"ko\": \"íƒ€ì„ë¼ì¸ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\", \"en\": \"Could not display timeline data\"},\n",
        "    \"fatigue_warning\": {\"ko\": \"í”¼ë¡œë„ íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\", \"en\": \"No fatigue timeline data available.\"},\n",
        "    \"network_subheader\": {\"ko\": \"ê°ˆë“± ë„¤íŠ¸ì›Œí¬ ë§µ (Conflict Network Map)\", \"en\": \"Conflict Network Map\"},\n",
        "    \"network_info\": {\"ko\": \"íŒ€ì› ê°„ ìƒí˜¸ì‘ìš©ì˜ ì§ˆì„ ë¶„ì„í•˜ì—¬ ì ì¬ì  ê°ˆë“± ë° í˜‘ë ¥ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. (ê·¸ë˜í”„ëŠ” ë§ˆìš°ìŠ¤ë¡œ ì¡°ì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤)\", \"en\": \"Predicts potential conflicts and collaborations by analyzing the quality of interactions. (The graph is interactive).\"},\n",
        "    \"network_error\": {\"ko\": \"ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ë¥¼ ë Œë”ë§í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ\", \"en\": \"Error rendering network graph\"},\n",
        "    \"network_warning\": {\"ko\": \"ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\", \"en\": \"Could not generate network data.\"},\n",
        "    # DataFrame Columns\n",
        "    \"col_name\": {\"ko\": \"ì´ë¦„\", \"en\": \"Name\"},\n",
        "    \"col_emotion\": {\"ko\": \"ê°ì • ê³„ìˆ˜\", \"en\": \"Emotion Score\"},\n",
        "    \"col_cognition\": {\"ko\": \"ì‚¬ê³  ê³„ìˆ˜\", \"en\": \"Cognition Score\"},\n",
        "    \"col_expression\": {\"ko\": \"í‘œí˜„ ê³„ìˆ˜\", \"en\": \"Expression Score\"},\n",
        "    \"col_value\": {\"ko\": \"ê°€ì¹˜ ê³„ìˆ˜\", \"en\": \"Value Score\"},\n",
        "    \"col_bias\": {\"ko\": \"í¸í–¥ ê³„ìˆ˜\", \"en\": \"Bias Score\"},\n",
        "    \"col_role\": {\"ko\": \"í•µì‹¬ ì—­í• \", \"en\": \"Core Role\"},\n",
        "}\n",
        "\n",
        "# --- Page Config ---\n",
        "st.set_page_config(\n",
        "    page_title=TEXTS[\"page_title\"][\"en\"],\n",
        "    page_icon=\"ğŸ¤–\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# --- Initialize Session State ---\n",
        "if 'analysis_result' not in st.session_state:\n",
        "    st.session_state.analysis_result = {}\n",
        "if 'api_key_configured' not in st.session_state:\n",
        "    st.session_state.api_key_configured = False\n",
        "if 'lang' not in st.session_state:\n",
        "    st.session_state.lang = 'ko'\n",
        "\n",
        "# --- Sidebar for Settings ---\n",
        "with st.sidebar:\n",
        "    st.header(TEXTS[\"sidebar_header\"][st.session_state.lang])\n",
        "\n",
        "    # Language Selector\n",
        "    lang_choice = st.selectbox(\n",
        "        label=f'{TEXTS[\"language_selector\"][\"en\"]} / {TEXTS[\"language_selector\"][\"ko\"]}',\n",
        "        options=['í•œêµ­ì–´', 'English'],\n",
        "        index=0 if st.session_state.lang == 'ko' else 1,\n",
        "        key='lang_selector'\n",
        "    )\n",
        "    st.session_state.lang = 'ko' if lang_choice == 'í•œêµ­ì–´' else 'en'\n",
        "    lang = st.session_state.lang\n",
        "\n",
        "    # API Key Management\n",
        "    try:\n",
        "        api_key = st.secrets[\"GEMINI_API_KEY\"]\n",
        "        st.success(TEXTS[\"api_key_loaded\"][lang])\n",
        "    except (FileNotFoundError, KeyError):\n",
        "        st.warning(TEXTS[\"local_env_warning\"][lang])\n",
        "        api_key = st.text_input(TEXTS[\"api_key_input\"][lang], type=\"password\", key=\"api_key_input\")\n",
        "\n",
        "    if api_key and not st.session_state.api_key_configured:\n",
        "        try:\n",
        "            genai.configure(api_key=api_key)\n",
        "            st.session_state.api_key_configured = True\n",
        "            st.success(TEXTS[\"api_key_success\"][lang])\n",
        "        except Exception as e:\n",
        "            st.error(f\"{TEXTS['api_key_failure'][lang]}: {e}\")\n",
        "\n",
        "    if not st.session_state.api_key_configured:\n",
        "        st.info(TEXTS[\"api_key_info\"][lang])\n",
        "\n",
        "# --- Main UI ---\n",
        "lang = st.session_state.lang\n",
        "st.title(TEXTS[\"main_title\"][lang])\n",
        "st.markdown(TEXTS[\"main_description\"][lang])\n",
        "\n",
        "# Prompts remain in Korean as they are optimized for analyzing Korean text.\n",
        "# (Prompts are omitted here for brevity, they are the same as before)\n",
        "PROMPT_TEAM_PROFILE = \"\"\"...\"\"\" # Same as before\n",
        "PROMPT_FATIGUE_TIMELINE = \"\"\"...\"\"\" # Same as before\n",
        "PROMPT_CONFLICT_NETWORK = \"\"\"...\"\"\" # Same as before\n",
        "\n",
        "# (Parser, API Caller, and Graphing functions are omitted for brevity, they are the same as before)\n",
        "def parse_kakao_talk(file_content):\n",
        "    \"\"\"...\"\"\" # Same as before\n",
        "    pattern = re.compile(r\"--------------- (\\d{4}ë…„ \\d{1,2}ì›” \\d{1,2}ì¼) \")\n",
        "    chat_lines = file_content.split('\\n')\n",
        "    data, current_date = [], None\n",
        "    for line in chat_lines:\n",
        "        date_match = pattern.match(line)\n",
        "        if date_match:\n",
        "            current_date_str = date_match.group(1)\n",
        "            current_date = datetime.strptime(current_date_str, \"%Yë…„ %mì›” %dì¼\").date()\n",
        "        elif line.startswith('[') and current_date:\n",
        "            try:\n",
        "                parts = line.split('] ', 2)\n",
        "                if len(parts) == 3:\n",
        "                    data.append({\"date\": current_date, \"speaker\": parts[0][1:], \"message\": parts[2]})\n",
        "            except (IndexError, ValueError): continue\n",
        "    return pd.DataFrame(data) if data else None\n",
        "\n",
        "def call_gemini_api(prompt, chat_log):\n",
        "    \"\"\"...\"\"\" # Same as before\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    full_prompt = prompt.format(chat_log=chat_log)\n",
        "    try:\n",
        "        response = model.generate_content(full_prompt)\n",
        "        cleaned_text = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "        return json.loads(cleaned_text)\n",
        "    except Exception as e:\n",
        "        st.error(f\"API Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def draw_network_graph(network_data):\n",
        "    \"\"\"...\"\"\" # Same as before\n",
        "    if not network_data or 'nodes' not in network_data or 'edges' not in network_data:\n",
        "        st.warning(TEXTS[\"network_warning\"][st.session_state.lang])\n",
        "        return\n",
        "    net = Network(height=\"600px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", notebook=True, directed=False)\n",
        "    color_map = {\"high_risk\": \"#FF4136\", \"medium_risk\": \"#FF851B\", \"potential_risk\": \"#FFDC00\", \"stable\": \"#DDDDDD\"}\n",
        "    for node in network_data['nodes']: net.add_node(node['id'], label=node['label'], size=25)\n",
        "    for edge in network_data['edges']:\n",
        "        edge_type = edge.get('type', 'stable')\n",
        "        net.add_edge(edge['from'], edge['to'], color=color_map.get(edge_type, \"#DDDDDD\"), width=4 if edge_type == 'high_risk' else 2)\n",
        "    try:\n",
        "        net.save_graph(\"network_graph.html\")\n",
        "        with open(\"network_graph.html\", 'r', encoding='utf-8') as f: html_content = f.read()\n",
        "        components.html(html_content, height=620)\n",
        "    except Exception as e: st.error(f\"{TEXTS['network_error'][st.session_state.lang]}: {e}\")\n",
        "\n",
        "\n",
        "st.header(TEXTS[\"upload_header\"][lang])\n",
        "st.info(TEXTS[\"upload_info\"][lang])\n",
        "\n",
        "uploaded_file = st.file_uploader(TEXTS[\"file_uploader_label\"][lang], type=\"txt\", key=\"file_uploader\")\n",
        "\n",
        "if uploaded_file is not None and st.session_state.api_key_configured:\n",
        "    try:\n",
        "        file_content = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "        chat_df = parse_kakao_talk(file_content)\n",
        "\n",
        "        if chat_df is not None:\n",
        "            st.success(TEXTS[\"parsing_success\"][lang].format(count=len(chat_df)))\n",
        "\n",
        "            if st.button(TEXTS[\"analysis_button\"][lang], key=\"start_analysis\"):\n",
        "                chat_log_for_api = \"\\n\".join(chat_df.apply(lambda row: f\"[{row['speaker']}] {row['message']}\", axis=1))\n",
        "\n",
        "                with st.spinner(TEXTS[\"spinner_profile\"][lang]):\n",
        "                    st.session_state.analysis_result['profile'] = call_gemini_api(PROMPT_TEAM_PROFILE, chat_log_for_api)\n",
        "                with st.spinner(TEXTS[\"spinner_timeline\"][lang]):\n",
        "                    st.session_state.analysis_result['timeline'] = call_gemini_api(PROMPT_FATIGUE_TIMELINE, chat_log_for_api)\n",
        "                with st.spinner(TEXTS[\"spinner_network\"][lang]):\n",
        "                    st.session_state.analysis_result['network'] = call_gemini_api(PROMPT_CONFLICT_NETWORK, chat_log_for_api)\n",
        "\n",
        "                st.success(TEXTS[\"analysis_complete\"][lang])\n",
        "        else:\n",
        "            st.error(TEXTS[\"parsing_error\"][lang])\n",
        "    except Exception as e:\n",
        "        st.error(f\"{TEXTS['file_process_error'][lang]}: {e}\")\n",
        "\n",
        "# --- Display Results in Tabs ---\n",
        "if st.session_state.analysis_result:\n",
        "    st.header(TEXTS[\"results_header\"][lang])\n",
        "\n",
        "    tab_titles = [TEXTS[\"tab_profile\"][lang], TEXTS[\"tab_fatigue\"][lang], TEXTS[\"tab_network\"][lang]]\n",
        "    tab1, tab2, tab3 = st.tabs(tab_titles)\n",
        "\n",
        "    with tab1:\n",
        "        st.subheader(TEXTS[\"profile_subheader\"][lang])\n",
        "        st.info(TEXTS[\"profile_info\"][lang])\n",
        "        profile_data = st.session_state.analysis_result.get('profile')\n",
        "        if profile_data:\n",
        "            try:\n",
        "                profile_df = pd.DataFrame(profile_data)\n",
        "                # Rename columns for multilingual support\n",
        "                profile_df.rename(columns={\n",
        "                    \"name\": TEXTS['col_name'][lang],\n",
        "                    \"emotion_score\": TEXTS['col_emotion'][lang],\n",
        "                    \"cognition_score\": TEXTS['col_cognition'][lang],\n",
        "                    \"expression_score\": TEXTS['col_expression'][lang],\n",
        "                    \"value_score\": TEXTS['col_value'][lang],\n",
        "                    \"bias_score\": TEXTS['col_bias'][lang],\n",
        "                    \"core_role\": TEXTS['col_role'][lang],\n",
        "                }, inplace=True)\n",
        "                st.dataframe(profile_df, use_container_width=True)\n",
        "            except Exception as e:\n",
        "                st.error(f\"{TEXTS['profile_error'][lang]}: {e}\")\n",
        "                st.json(profile_data)\n",
        "        else:\n",
        "            st.warning(TEXTS[\"profile_warning\"][lang])\n",
        "\n",
        "    with tab2:\n",
        "        st.subheader(TEXTS[\"fatigue_subheader\"][lang])\n",
        "        st.info(TEXTS[\"fatigue_info\"][lang])\n",
        "        timeline_data = st.session_state.analysis_result.get('timeline')\n",
        "        if timeline_data:\n",
        "            try:\n",
        "                timeline_df = pd.DataFrame.from_dict(timeline_data, orient='index')\n",
        "                timeline_df.index = pd.to_datetime(timeline_df.index)\n",
        "                timeline_df = timeline_df.sort_index()\n",
        "                st.line_chart(timeline_df)\n",
        "            except Exception as e:\n",
        "                st.error(f\"{TEXTS['fatigue_error'][lang]}: {e}\")\n",
        "                st.json(timeline_data)\n",
        "        else:\n",
        "            st.warning(TEXTS[\"fatigue_warning\"][lang])\n",
        "\n",
        "    with tab3:\n",
        "        st.subheader(TEXTS[\"network_subheader\"][lang])\n",
        "        st.info(TEXTS[\"network_info\"][lang])\n",
        "        network_data = st.session_state.analysis_result.get('network')\n",
        "        if network_data:\n",
        "            draw_network_graph(network_data)\n",
        "        else:\n",
        "            st.warning(TEXTS[\"network_warning\"][lang])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "SWo9spb1BFIf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}