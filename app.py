# app.py
# Ïó≠Ìï†: Ï†ÑÏ≤¥ ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Í¥ÄÎ¶¨ÌïòÍ≥†, ÌÖçÏä§Ìä∏ÏôÄ Îç∞Ïù¥ÌÑ∞Î•º Í≤∞Ìï©ÌïòÏó¨ ÏµúÏ¢Ö Î≥¥Í≥†ÏÑúÎ•º Î†åÎçîÎßÅÌï©ÎãàÎã§.
# ÏµúÏ¢Ö Î≤ÑÏ†Ñ: AIÍ∞Ä ÏÉùÏÑ±Ìïú ÌÖçÏä§Ìä∏ÏôÄ Ïï±Ïù¥ ÏÉùÏÑ±Ìïú Í∑∏ÎûòÌîÑÎ•º Í≤∞Ìï©ÌïòÏó¨ ÌïòÎÇòÏùò ÏôÑÏÑ±Îêú Î≥¥Í≥†ÏÑúÎ•º Ï∂úÎ†•Ìï©ÎãàÎã§.

import streamlit as st
import pandas as pd
import google.generativeai as genai
from pyvis.network import Network
import streamlit.components.v1 as components

# We no longer need a separate parser file.
import analyzer

# --- TEXTS ÎîïÏÖîÎÑàÎ¶¨Îäî Ïù¥Ï†ÑÍ≥º ÎèôÏùº (ÏÉùÎûµ) ---
TEXTS = {
    "page_title": {"ko": "MirrorOrg MVP", "en": "MirrorOrg MVP"},
    "main_title": {"ko": "ü™û MirrorOrg MVP: Ï¢ÖÌï© ÌåÄ Î∂ÑÏÑù", "en": "ü™û MirrorOrg MVP: Comprehensive Team Analysis"},
    "main_description": {
        "ko": "'ÎØ∏Îü¨Ïò§ÏïåÏßÄ ÌåÄ Î∂ÑÏÑù ÏÇ¨Î°Ä'Ïóê Í∏∞Î∞òÌïú Îã§Ï∞®Ïõê ÌòëÏóÖ ÏßÑÎã® ÎèÑÍµ¨ÏûÖÎãàÎã§.\n**ÌåÄ Ï±ÑÌåÖ Í∏∞Î°ù(Ïπ¥Ïπ¥Ïò§ÌÜ°, Ïä¨Îûô Îì±)**ÏùÑ ÏóÖÎ°úÎìúÌïòÏó¨ Ï¢ÖÌï© Î∂ÑÏÑù Î≥¥Í≥†ÏÑúÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.",
        "en": "A multi-dimensional collaboration diagnostic tool based on the 'MirrorOrg Team Analysis Case Study'.\nUpload your **team chat history (e.g., KakaoTalk, Slack)** to generate a comprehensive analysis report."
    },
    "sidebar_header": {"ko": "ÏÑ§Ï†ï", "en": "Settings"},
    "language_selector": {"ko": "Ïñ∏Ïñ¥", "en": "Language"},
    "api_key_error_title": {"ko": "API ÌÇ§ ÏÑ§Ï†ï Ïò§Î•ò", "en": "API Key Configuration Error"},
    "api_key_error_body": {
        "ko": "Ïï± Í¥ÄÎ¶¨ÏûêÍ∞Ä ÏÑ§Ï†ïÌïú API ÌÇ§Ïóê Î¨∏Ï†úÍ∞Ä ÏûàÏäµÎãàÎã§. Streamlit CloudÏùò 'Secrets' ÏÑ§Ï†ïÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.",
        "en": "There is an issue with the API key configured by the app administrator. Please check the 'Secrets' settings on Streamlit Cloud."
    },
    "upload_header": {"ko": "1. Ï±ÑÌåÖ Í∏∞Î°ù ÏóÖÎ°úÎìú", "en": "1. Upload Chat History"},
    "upload_info": {
        "ko": "ÌåÄ Ï±ÑÌåÖ Í∏∞Î°ùÏùÑ ÌÖçÏä§Ìä∏(.txt) ÌååÏùºÎ°ú ÏóÖÎ°úÎìúÌïòÏÑ∏Ïöî. Îã§ÏñëÌïú ÌòïÏãùÏùÑ ÏßÄÏõêÌï©ÎãàÎã§.",
        "en": "Upload your team chat history as a text (.txt) file. Various formats are supported."
    },
    "file_uploader_label": {"ko": "Î∂ÑÏÑùÌï† .txt ÌååÏùºÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.", "en": "Choose a .txt file to analyze."},
    "analysis_button": {"ko": "Ï¢ÖÌï© Î∂ÑÏÑù Î≥¥Í≥†ÏÑú ÏÉùÏÑ±ÌïòÍ∏∞", "en": "Generate Comprehensive Report"},
    "spinner_data": {"ko": "1/2: ÏãúÍ∞ÅÌôîÎ•º ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú Ï§ë...", "en": "1/2: Extracting data for visualizations..."},
    "spinner_report": {"ko": "2/2: Î≥¥Í≥†ÏÑú ÌÖçÏä§Ìä∏ ÏûëÏÑ± Ï§ë...", "en": "2/2: Writing report narrative..."},
    "analysis_complete": {"ko": "‚úÖ Î≥¥Í≥†ÏÑú ÏÉùÏÑ±Ïù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§!", "en": "‚úÖ Report generation complete!"},
    "file_process_error": {"ko": "ÌååÏùº Ï≤òÎ¶¨ Ï§ë Ïïå Ïàò ÏóÜÎäî Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§", "en": "An unknown error occurred while processing the file"},
    "results_header": {"ko": "2. Ï¢ÖÌï© Î∂ÑÏÑù Î≥¥Í≥†ÏÑú", "en": "2. Comprehensive Analysis Report"},
    "raw_response_error": {"ko": "LLMÏù¥ Ïú†Ìö®Ìïú Îç∞Ïù¥ÌÑ∞Î•º Î∞òÌôòÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§. ÏïÑÎûòÎäî LLMÏùò ÏõêÎ≥∏ ÏùëÎãµÏûÖÎãàÎã§.", "en": "The LLM did not return valid data. Below is the raw response from the LLM."}
}

# --- Page Config & Initialization ---
st.set_page_config(page_title=TEXTS["page_title"]["en"], page_icon="ü§ñ", layout="wide")
if 'lang' not in st.session_state: st.session_state.lang = 'ko'
if 'report_text' not in st.session_state: st.session_state.report_text = None
if 'graph_data' not in st.session_state: st.session_state.graph_data = None

# --- Sidebar ---
with st.sidebar:
    st.header(TEXTS["sidebar_header"][st.session_state.lang])
    lang_choice = st.selectbox(
        label=f'{TEXTS["language_selector"]["en"]} / {TEXTS["language_selector"]["ko"]}',
        options=['ÌïúÍµ≠Ïñ¥', 'English'],
        index=0 if st.session_state.lang == 'ko' else 1
    )
    st.session_state.lang = 'ko' if lang_choice == 'ÌïúÍµ≠Ïñ¥' else 'en'
lang = st.session_state.lang

# --- API Key Configuration ---
api_configured = False
try:
    genai.configure(api_key=st.secrets["GOOGLE_AI_API_KEY"])
    api_configured = True
except (KeyError, AttributeError):
    st.error(TEXTS["api_key_error_title"][lang])
    st.warning(TEXTS["api_key_error_body"][lang])

# --- UI Rendering Functions ---
def draw_network_graph(network_data):
    net = Network(height="600px", width="100%", bgcolor="#222222", font_color="white", notebook=True, directed=False)
    color_map = {"high_risk": "#FF4136", "medium_risk": "#FF851B", "potential_risk": "#FFDC00", "stable": "#DDDDDD"}
    for node in network_data.get('nodes', []): net.add_node(node.get('id'), label=node.get('label'), size=25)
    for edge in network_data.get('edges', []):
        edge_type = edge.get('type', 'stable')
        net.add_edge(edge.get('from'), edge.get('to'), color=color_map.get(edge_type, "#DDDDDD"), width=4 if edge_type == 'high_risk' else 2)
    try:
        net.save_graph("network_graph.html")
        with open("network_graph.html", 'r', encoding='utf-8') as f: html_content = f.read()
        components.html(html_content, height=620, scrolling=True)
    except Exception as e: st.error(f"Error rendering network graph: {e}")

# --- Main App UI ---
st.title(TEXTS["main_title"][lang])
st.markdown(TEXTS["main_description"][lang])

if api_configured:
    st.header(TEXTS["upload_header"][lang])
    st.info(TEXTS["upload_info"][lang])
    uploaded_file = st.file_uploader(TEXTS["file_uploader_label"][lang], type="txt")

    if uploaded_file:
        try:
            if 'uploaded_file_id' not in st.session_state or uploaded_file.file_id != st.session_state.uploaded_file_id:
                st.session_state.report_text = None
                st.session_state.graph_data = None
                st.session_state.uploaded_file_id = uploaded_file.file_id

            file_content = uploaded_file.getvalue().decode("utf-8")
            st.success(f"'{uploaded_file.name}' ÌååÏùºÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏóÖÎ°úÎìúÎêòÏóàÏäµÎãàÎã§. Ïù¥Ï†ú Î∂ÑÏÑù Î≤ÑÌäºÏùÑ ÎàåÎü¨Ï£ºÏÑ∏Ïöî.")
            
            if st.button(TEXTS["analysis_button"][lang]):
                with st.spinner(TEXTS["spinner_data"][lang]):
                    st.session_state.graph_data = analyzer.generate_graph_data(file_content)
                with st.spinner(TEXTS["spinner_report"][lang]):
                    st.session_state.report_text = analyzer.generate_report_text(file_content, lang=lang)
                st.success(TEXTS["analysis_complete"][lang])

        except Exception as e:
            st.error(f"{TEXTS['file_process_error'][lang]}: {e}")
    else:
        st.session_state.report_text = None
        st.session_state.graph_data = None
        st.session_state.uploaded_file_id = None

    # --- Display Report ---
    if st.session_state.report_text and st.session_state.graph_data:
        st.header(TEXTS["results_header"][lang])
        st.markdown("---")

        # Split the report text to inject visualizations
        report_parts = st.session_state.report_text.split("---")
        graph_data = st.session_state.graph_data

        # Check if graph_data is valid
        if isinstance(graph_data, dict):
            # Render part 1: Overview
            st.markdown(report_parts[0], unsafe_allow_html=True)

            # Render part 2: Diagnosis with Profile Table
            if len(report_parts) > 1:
                st.markdown(report_parts[1], unsafe_allow_html=True)
                profile_data = graph_data.get('profile_data')
                if isinstance(profile_data, list):
                    st.dataframe(pd.DataFrame(profile_data), use_container_width=True)
                else:
                    st.error(TEXTS["raw_response_error"][lang])
                    st.code(profile_data, language=None)

            # Render part 3: Prediction with Timeline and Network
            if len(report_parts) > 2:
                st.markdown(report_parts[2], unsafe_allow_html=True)
                
                # Fatigue Timeline
                timeline_data = graph_data.get('timeline_data')
                if isinstance(timeline_data, dict):
                    try:
                        df = pd.DataFrame.from_dict(timeline_data, orient='index')
                        df.index = pd.to_datetime(df.index).strftime('%Y-%m-%d')
                        st.line_chart(df.sort_index())
                    except Exception:
                        st.error(TEXTS["raw_response_error"][lang])
                        st.json(timeline_data)
                
                # Relationship Network
                network_data = graph_data.get('network_data')
                if isinstance(network_data, dict):
                    draw_network_graph(network_data)
                else:
                    st.error(TEXTS["raw_response_error"][lang])
                    st.code(network_data, language=None)

            # Render part 4: Conclusion
            if len(report_parts) > 3:
                st.markdown("---")
                st.markdown(report_parts[3], unsafe_allow_html=True)
        
        else: # If graph_data itself is not a dict (i.e., an error string)
            st.error(TEXTS["raw_response_error"][lang])
            st.code(graph_data, language=None)
            st.markdown("---")
            st.markdown("### Î≥¥Í≥†ÏÑú ÌÖçÏä§Ìä∏ (Ï∞∏Í≥†)")
            st.markdown(st.session_state.report_text)
