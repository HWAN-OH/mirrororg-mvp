# app.py
# ì—­í• : ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•˜ê³ , ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
# ìµœì¢… ë²„ì „: ê° ë¶„ì„ì„ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì•ˆì •ì„±ê³¼ ì‚¬ìš©ì ê²½í—˜ì„ ê°œì„ í•©ë‹ˆë‹¤.

import streamlit as st
import pandas as pd
from pyvis.network import Network
import streamlit.components.v1 as components
import google.generativeai as genai

import parsers
import analyzer

# --- TEXTS ë”•ì…”ë„ˆë¦¬ëŠ” ì´ì „ê³¼ ë™ì¼ (ìƒëµ) ---
TEXTS = {
    "page_title": {"ko": "MirrorOrg MVP", "en": "MirrorOrg MVP"},
    "main_title": {"ko": "ğŸª MirrorOrg MVP: ì¢…í•© íŒ€ ë¶„ì„", "en": "ğŸª MirrorOrg MVP: Comprehensive Team Analysis"},
    "main_description": {
        "ko": "'ë¯¸ëŸ¬ì˜¤ì•Œì§€ íŒ€ ë¶„ì„ ì‚¬ë¡€'ì— ê¸°ë°˜í•œ ë‹¤ì°¨ì› í˜‘ì—… ì§„ë‹¨ ë„êµ¬ì…ë‹ˆë‹¤.\n**íŒ€ ì±„íŒ… ê¸°ë¡(ì¹´ì¹´ì˜¤í†¡, ìŠ¬ë™ ë“±)**ì„ ì—…ë¡œë“œí•˜ì—¬ íŒ€ í”„ë¡œí•„, í”¼ë¡œë„ ë³€í™”, ê´€ê³„ ë„¤íŠ¸ì›Œí¬ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì§„ë‹¨í•©ë‹ˆë‹¤.",
        "en": "A multi-dimensional collaboration diagnostic tool based on the 'MirrorOrg Team Analysis Case Study'.\nUpload your **team chat history (e.g., KakaoTalk, Slack)** to diagnose Team Profile, Fatigue Trajectory, and Relationship Network."
    },
    "sidebar_header": {"ko": "ì„¤ì •", "en": "Settings"},
    "language_selector": {"ko": "ì–¸ì–´", "en": "Language"},
    "api_key_error_title": {"ko": "API í‚¤ ì„¤ì • ì˜¤ë¥˜", "en": "API Key Configuration Error"},
    "api_key_error_body": {
        "ko": "ì•± ê´€ë¦¬ìê°€ ì„¤ì •í•œ API í‚¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. Streamlit Cloudì˜ 'Secrets' ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "en": "There is an issue with the API key configured by the app administrator. Please check the 'Secrets' settings on Streamlit Cloud."
    },
    "upload_header": {"ko": "1. ì±„íŒ… ê¸°ë¡ ì—…ë¡œë“œ", "en": "1. Upload Chat History"},
    "upload_info": {
        "ko": "íŒ€ ì±„íŒ… ê¸°ë¡ì„ í…ìŠ¤íŠ¸(.txt) íŒŒì¼ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”. í˜„ì¬ **ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” í˜•ì‹**ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
        "en": "Upload your team chat history as a text (.txt) file. Currently optimized for the **KakaoTalk chat format**."
    },
    "file_uploader_label": {"ko": "ë¶„ì„í•  .txt íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", "en": "Choose a .txt file to analyze."},
    "parsing_success": {"ko": "íŒŒì¼ íŒŒì‹± ì„±ê³µ! {count}ê°œì˜ ë©”ì‹œì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ({format} í˜•ì‹)", "en": "File parsed successfully! Found {count} messages. (Format: {format})"},
    "parsing_error": {"ko": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì´ê±°ë‚˜ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "en": "The file format is not supported or the file may be corrupted."},
    "analysis_button": {"ko": "{analysis_type} ë¶„ì„í•˜ê¸°", "en": "Analyze {analysis_type}"},
    "spinner_analysis": {"ko": "{analysis_type} ë¶„ì„ ì¤‘...", "en": "Analyzing {analysis_type}..."},
    "analysis_complete": {"ko": "âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", "en": "âœ… Analysis complete!"},
    "file_process_error": {"ko": "íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", "en": "An unknown error occurred while processing the file"},
    "results_header": {"ko": "2. ì§„ë‹¨ ê²°ê³¼", "en": "2. Diagnostic Results"},
    "tab_profile": {"ko": "**íŒ€ í”„ë¡œí•„ (ì§„ë‹¨)**", "en": "**Team Profile (Diagnosis)**"},
    "tab_fatigue": {"ko": "**í”¼ë¡œë„ ë³€í™” (ì˜ˆì¸¡)**", "en": "**Fatigue Trajectory (Prediction)**"},
    "tab_network": {"ko": "**ê´€ê³„ ë„¤íŠ¸ì›Œí¬ (ì˜ˆì¸¡)**", "en": "**Relationship Network (Prediction)**"},
    "profile_subheader": {"ko": "ì •ì²´ì„± ê³„ìˆ˜ ë§µ", "en": "Identity Coefficient Map"},
    "profile_info": {"ko": "íŒ€ì›ë“¤ì˜ ì„±í–¥ê³¼ ì—­í• ì„ íŒŒì•…í•˜ì—¬ íŒ€ì˜ ì „ì²´ì ì¸ êµ¬ì„±ì„ ì§„ë‹¨í•©ë‹ˆë‹¤.", "en": "Diagnoses the overall team composition by identifying member traits and roles."},
    "profile_error": {"ko": "í”„ë¡œí•„ ë°ì´í„°ë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", "en": "An error occurred while displaying profile data"},
    "profile_warning": {"ko": "íŒ€ í”„ë¡œí•„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.", "en": "No team profile data. Please press the analyze button."},
    "fatigue_subheader": {"ko": "í”¼ë¡œë„ ì‹œê³„ì—´ ê·¸ë˜í”„", "en": "Fatigue Timeline Graph"},
    "fatigue_info": {"ko": "ì‹œê°„ì— ë”°ë¥¸ íŒ€ì›ë“¤ì˜ ê°ì •ì , ì—…ë¬´ì  ì†Œì§„ ìƒíƒœì˜ ë³€í™”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.", "en": "Predicts the changes in team members' emotional and professional burnout over time."},
    "fatigue_error": {"ko": "íƒ€ì„ë¼ì¸ ë°ì´í„°ë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", "en": "An error occurred while displaying timeline data"},
    "fatigue_warning": {"ko": "í”¼ë¡œë„ íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.", "en": "No fatigue timeline data. Please press the analyze button."},
    "network_subheader": {"ko": "ê°ˆë“± ë„¤íŠ¸ì›Œí¬ ë§µ", "en": "Conflict Network Map"},
    "network_info": {"ko": "íŒ€ì› ê°„ ìƒí˜¸ì‘ìš©ì˜ ì§ˆì„ ë¶„ì„í•˜ì—¬ ì ì¬ì  ê°ˆë“± ë° í˜‘ë ¥ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. (ê·¸ë˜í”„ëŠ” ë§ˆìš°ìŠ¤ë¡œ ì¡°ì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤)", "en": "Predicts potential conflicts and collaborations by analyzing the quality of interactions. (The graph is interactive)."},
    "network_error": {"ko": "ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ë¥¼ ë Œë”ë§í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", "en": "Error rendering network graph"},
    "network_warning": {"ko": "ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.", "en": "Could not generate network data. Please press the analyze button."},
    "col_name": {"ko": "ì´ë¦„", "en": "Name"},
    "col_emotion": {"ko": "ê°ì • ê³„ìˆ˜", "en": "Emotion Score"},
    "col_cognition": {"ko": "ì‚¬ê³  ê³„ìˆ˜", "en": "Cognition Score"},
    "col_expression": {"ko": "í‘œí˜„ ê³„ìˆ˜", "en": "Expression Score"},
    "col_value": {"ko": "ê°€ì¹˜ ê³„ìˆ˜", "en": "Value Score"},
    "col_bias": {"ko": "í¸í–¥ ê³„ìˆ˜", "en": "Bias Score"},
    "col_role": {"ko": "í•µì‹¬ ì—­í• ", "en": "Core Role"},
    "raw_response_error": {"ko": "LLMì´ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” LLMì˜ ì›ë³¸ ì‘ë‹µì…ë‹ˆë‹¤.", "en": "The LLM did not return valid JSON. Below is the raw response from the LLM."}
}

# --- Page Config & Initialization ---
st.set_page_config(page_title=TEXTS["page_title"]["en"], page_icon="ğŸ¤–", layout="wide")
if 'lang' not in st.session_state:
    st.session_state.lang = 'ko'
# Initialize session state for each analysis type
if 'profile_result' not in st.session_state:
    st.session_state.profile_result = None
if 'timeline_result' not in st.session_state:
    st.session_state.timeline_result = None
if 'network_result' not in st.session_state:
    st.session_state.network_result = None
if 'chat_df' not in st.session_state:
    st.session_state.chat_df = None

# --- Sidebar ---
with st.sidebar:
    st.header(TEXTS["sidebar_header"][st.session_state.lang])
    lang_choice = st.selectbox(
        label=f'{TEXTS["language_selector"]["en"]} / {TEXTS["language_selector"]["ko"]}',
        options=['í•œêµ­ì–´', 'English'],
        index=0 if st.session_state.lang == 'ko' else 1
    )
    st.session_state.lang = 'ko' if lang_choice == 'í•œêµ­ì–´' else 'en'
lang = st.session_state.lang

# --- API Key Configuration ---
api_configured = False
try:
    genai.configure(api_key=st.secrets["GOOGLE_AI_API_KEY"])
    api_configured = True
except (KeyError, AttributeError):
    st.error(TEXTS["api_key_error_title"][lang])
    st.warning(TEXTS["api_key_error_body"][lang])

# --- UI Rendering Functions ---
def draw_network_graph(network_data, lang):
    if not network_data or 'nodes' not in network_data or 'edges' not in network_data:
        st.warning(TEXTS["network_warning"][lang])
        return
    net = Network(height="600px", width="100%", bgcolor="#222222", font_color="white", notebook=True, directed=False)
    color_map = {"high_risk": "#FF4136", "medium_risk": "#FF851B", "potential_risk": "#FFDC00", "stable": "#DDDDDD"}
    for node in network_data.get('nodes', []): net.add_node(node.get('id'), label=node.get('label'), size=25)
    for edge in network_data.get('edges', []):
        edge_type = edge.get('type', 'stable')
        net.add_edge(edge.get('from'), edge.get('to'), color=color_map.get(edge_type, "#DDDDDD"), width=4 if edge_type == 'high_risk' else 2)
    try:
        net.save_graph("network_graph.html")
        with open("network_graph.html", 'r', encoding='utf-8') as f: html_content = f.read()
        components.html(html_content, height=620)
    except Exception as e: st.error(f"{TEXTS['network_error'][lang]}: {e}")

# --- Main App UI ---
st.title(TEXTS["main_title"][lang])
st.markdown(TEXTS["main_description"][lang])

if api_configured:
    st.header(TEXTS["upload_header"][lang])
    st.info(TEXTS["upload_info"][lang])
    uploaded_file = st.file_uploader(TEXTS["file_uploader_label"][lang], type="txt")

    if uploaded_file is not None:
        try:
            file_content = uploaded_file.getvalue().decode("utf-8")
            st.session_state.chat_df = parsers.parse(file_content)

            if isinstance(st.session_state.chat_df, pd.DataFrame):
                detected_format = parsers.detect_format(file_content)
                st.success(TEXTS["parsing_success"][lang].format(count=len(st.session_state.chat_df), format=detected_format))
            else:
                st.error(TEXTS["parsing_error"][lang])
                st.session_state.chat_df = None # Clear df on parsing error
        except Exception as e:
            st.error(f"{TEXTS['file_process_error'][lang]}: {e}")
            st.session_state.chat_df = None

    # --- Display Results in Tabs ---
    if st.session_state.chat_df is not None:
        st.header(TEXTS["results_header"][lang])
        tab_titles = [TEXTS["tab_profile"][lang], TEXTS["tab_fatigue"][lang], TEXTS["tab_network"][lang]]
        tab1, tab2, tab3 = st.tabs(tab_titles)

        with tab1:
            st.subheader(TEXTS["profile_subheader"][lang])
            st.info(TEXTS["profile_info"][lang])
            
            if st.button(TEXTS["analysis_button"][lang].format(analysis_type="íŒ€ í”„ë¡œí•„")):
                with st.spinner(TEXTS["spinner_analysis"][lang].format(analysis_type="íŒ€ í”„ë¡œí•„")):
                    st.session_state.profile_result = analyzer.analyze_profile(st.session_state.chat_df)
            
            profile_data = st.session_state.profile_result
            if isinstance(profile_data, list):
                try:
                    profile_df = pd.DataFrame(profile_data)
                    st.dataframe(profile_df, use_container_width=True)
                except Exception as e:
                    st.error(f"{TEXTS['profile_error'][lang]}: {e}")
            elif isinstance(profile_data, str):
                st.error(TEXTS["raw_response_error"][lang])
                st.code(profile_data, language=None)
            else:
                st.warning(TEXTS["profile_warning"][lang])

        with tab2:
            st.subheader(TEXTS["fatigue_subheader"][lang])
            st.info(TEXTS["fatigue_info"][lang])

            if st.button(TEXTS["analysis_button"][lang].format(analysis_type="í”¼ë¡œë„ ë³€í™”")):
                with st.spinner(TEXTS["spinner_analysis"][lang].format(analysis_type="í”¼ë¡œë„ ë³€í™”")):
                    st.session_state.timeline_result = analyzer.analyze_timeline(st.session_state.chat_df)

            timeline_data = st.session_state.timeline_result
            if isinstance(timeline_data, dict) and 'error' not in timeline_data:
                try:
                    timeline_df = pd.DataFrame.from_dict(timeline_data, orient='index')
                    timeline_df.index = pd.to_datetime(timeline_df.index).strftime('%Y-%m-%d')
                    st.line_chart(timeline_df.sort_index())
                except Exception as e:
                    st.error(f"{TEXTS['fatigue_error'][lang]}: {e}")
            elif isinstance(timeline_data, str):
                st.error(TEXTS["raw_response_error"][lang])
                st.code(timeline_data, language=None)
            else:
                st.warning(TEXTS["fatigue_warning"][lang])

        with tab3:
            st.subheader(TEXTS["network_subheader"][lang])
            st.info(TEXTS["network_info"][lang])

            if st.button(TEXTS["analysis_button"][lang].format(analysis_type="ê´€ê³„ ë„¤íŠ¸ì›Œí¬")):
                with st.spinner(TEXTS["spinner_analysis"][lang].format(analysis_type="ê´€ê³„ ë„¤íŠ¸ì›Œí¬")):
                    st.session_state.network_result = analyzer.analyze_network(st.session_state.chat_df)

            network_data = st.session_state.network_result
            if isinstance(network_data, dict) and 'nodes' in network_data:
                draw_network_graph(network_data, lang)
            elif isinstance(network_data, str):
                st.error(TEXTS["raw_response_error"][lang])
                st.code(network_data, language=None)
            else:
                st.warning(TEXTS["network_warning"][lang])
