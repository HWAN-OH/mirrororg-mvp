import streamlit as st
import google.generativeai as genai
import pandas as pd
import re
import json
from pyvis.network import Network
import streamlit.components.v1 as components
from datetime import datetime

# --- [Delta] Centralized Text Management for Multilingual Support ---
TEXTS = {
    # General UI
    "page_title": {"ko": "MirrorOrg MVP", "en": "MirrorOrg MVP"},
    "main_title": {"ko": "ğŸª MirrorOrg MVP: ì¢…í•© íŒ€ ë¶„ì„", "en": "ğŸª MirrorOrg MVP: Comprehensive Team Analysis"},
    "main_description": {
        "ko": "'ë¯¸ëŸ¬ì˜¤ì•Œì§€ íŒ€ ë¶„ì„ ì‚¬ë¡€'ì— ê¸°ë°˜í•œ ë‹¤ì°¨ì› í˜‘ì—… ì§„ë‹¨ ë„êµ¬ì…ë‹ˆë‹¤.\n**íŒ€ ì±„íŒ… ê¸°ë¡(ì¹´ì¹´ì˜¤í†¡, ìŠ¬ë™ ë“±)**ì„ ì—…ë¡œë“œí•˜ì—¬ íŒ€ í”„ë¡œí•„, í”¼ë¡œë„ ë³€í™”, ê´€ê³„ ë„¤íŠ¸ì›Œí¬ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì§„ë‹¨í•©ë‹ˆë‹¤.",
        "en": "A multi-dimensional collaboration diagnostic tool based on the 'MirrorOrg Team Analysis Case Study'.\nUpload your **team chat history (e.g., KakaoTalk, Slack)** to diagnose Team Profile, Fatigue Trajectory, and Relationship Network."
    },
    # Sidebar
    "sidebar_header": {"ko": "ì„¤ì •", "en": "Settings"},
    "language_selector": {"ko": "ì–¸ì–´", "en": "Language"},
    "api_key_error_title": {"ko": "API í‚¤ ì„¤ì • ì˜¤ë¥˜", "en": "API Key Configuration Error"},
    "api_key_error_body": {
        "ko": "ì•± ê´€ë¦¬ìê°€ ì„¤ì •í•œ API í‚¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. Streamlit Cloudì˜ 'Secrets' ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "en": "There is an issue with the API key configured by the app administrator. Please check the 'Secrets' settings on Streamlit Cloud."
    },
    # Main Content
    "upload_header": {"ko": "1. ì±„íŒ… ê¸°ë¡ ì—…ë¡œë“œ", "en": "1. Upload Chat History"},
    "upload_info": {
        "ko": "íŒ€ ì±„íŒ… ê¸°ë¡ì„ í…ìŠ¤íŠ¸(.txt) íŒŒì¼ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”. í˜„ì¬ **ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” í˜•ì‹**ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n**íŒ:** ì¹´ì¹´ì˜¤í†¡ì˜ ê²½ìš° 'ëŒ€í™” ë‚´ë³´ë‚´ê¸°' > 'í…ìŠ¤íŠ¸ íŒŒì¼ë§Œ' ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "en": "Upload your team chat history as a text (.txt) file. Currently optimized for the **KakaoTalk chat format**.\n**Tip:** For KakaoTalk, you can use the 'Export Chat' > 'Export Text Only' feature."
    },
    "file_uploader_label": {"ko": "ë¶„ì„í•  .txt íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", "en": "Choose a .txt file to analyze."},
    "parsing_success": {"ko": "íŒŒì¼ íŒŒì‹± ì„±ê³µ! {count}ê°œì˜ ë©”ì‹œì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.", "en": "File parsed successfully! Found {count} messages."},
    "parsing_error": {"ko": "ì¹´ì¹´ì˜¤í†¡ íŒŒì¼ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.", "en": "Could not recognize the KakaoTalk file format. Please check the file."},
    "analysis_button": {"ko": "ì¢…í•© ë¶„ì„ ì‹œì‘í•˜ê¸° ğŸš€", "en": "Start Comprehensive Analysis ğŸš€"},
    "spinner_profile": {"ko": "1/3: íŒ€ í”„ë¡œí•„ ë¶„ì„ ì¤‘...", "en": "1/3: Analyzing Team Profile..."},
    "spinner_timeline": {"ko": "2/3: í”¼ë¡œë„ íƒ€ì„ë¼ì¸ ë¶„ì„ ì¤‘...", "en": "2/3: Analyzing Fatigue Timeline..."},
    "spinner_network": {"ko": "3/3: ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì¤‘...", "en": "3/3: Analyzing Relationship Network..."},
    "analysis_complete": {"ko": "âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.", "en": "âœ… Analysis complete! Check the results in the tabs below."},
    "file_process_error": {"ko": "íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "en": "Error processing file"},
    # API Errors
    "api_parse_error": {"ko": "API ì‘ë‹µì„ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ì‘ë‹µ", "en": "Failed to parse API response. Original response"},
    "api_call_error": {"ko": "API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "en": "Error during API call"},
    # Results
    "results_header": {"ko": "2. ì§„ë‹¨ ê²°ê³¼", "en": "2. Diagnostic Results"},
    "tab_profile": {"ko": "**íŒ€ í”„ë¡œí•„ (ì§„ë‹¨)**", "en": "**Team Profile (Diagnosis)**"},
    "tab_fatigue": {"ko": "**í”¼ë¡œë„ ë³€í™” (ì˜ˆì¸¡)**", "en": "**Fatigue Trajectory (Prediction)**"},
    "tab_network": {"ko": "**ê´€ê³„ ë„¤íŠ¸ì›Œí¬ (ì˜ˆì¸¡)**", "en": "**Relationship Network (Prediction)**"},
    "profile_subheader": {"ko": "ì •ì²´ì„± ê³„ìˆ˜ ë§µ (Identity Coefficient Map)", "en": "Identity Coefficient Map"},
    "profile_info": {"ko": "íŒ€ì›ë“¤ì˜ ì„±í–¥ê³¼ ì—­í• ì„ íŒŒì•…í•˜ì—¬ íŒ€ì˜ ì „ì²´ì ì¸ êµ¬ì„±ì„ ì§„ë‹¨í•©ë‹ˆë‹¤.", "en": "Diagnoses the overall team composition by identifying member traits and roles."},
    "profile_error": {"ko": "í”„ë¡œí•„ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "en": "Could not display profile data"},
    "profile_warning": {"ko": "íŒ€ í”„ë¡œí•„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", "en": "No team profile data available."},
    "fatigue_subheader": {"ko": "í”¼ë¡œë„ ì‹œê³„ì—´ ê·¸ë˜í”„ (Fatigue Timeline)", "en": "Fatigue Timeline Graph"},
    "fatigue_info": {"ko": "ì‹œê°„ì— ë”°ë¥¸ íŒ€ì›ë“¤ì˜ ê°ì •ì , ì—…ë¬´ì  ì†Œì§„ ìƒíƒœì˜ ë³€í™”ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.", "en": "Predicts the changes in team members' emotional and professional burnout over time."},
    "fatigue_error": {"ko": "íƒ€ì„ë¼ì¸ ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "en": "Could not display timeline data"},
    "fatigue_warning": {"ko": "í”¼ë¡œë„ íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", "en": "No fatigue timeline data available."},
    "network_subheader": {"ko": "ê°ˆë“± ë„¤íŠ¸ì›Œí¬ ë§µ (Conflict Network Map)", "en": "Conflict Network Map"},
    "network_info": {"ko": "íŒ€ì› ê°„ ìƒí˜¸ì‘ìš©ì˜ ì§ˆì„ ë¶„ì„í•˜ì—¬ ì ì¬ì  ê°ˆë“± ë° í˜‘ë ¥ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. (ê·¸ë˜í”„ëŠ” ë§ˆìš°ìŠ¤ë¡œ ì¡°ì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤)", "en": "Predicts potential conflicts and collaborations by analyzing the quality of interactions. (The graph is interactive)."},
    "network_error": {"ko": "ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ë¥¼ ë Œë”ë§í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "en": "Error rendering network graph"},
    "network_warning": {"ko": "ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "en": "Could not generate network data."},
    # DataFrame Columns
    "col_name": {"ko": "ì´ë¦„", "en": "Name"},
    "col_emotion": {"ko": "ê°ì • ê³„ìˆ˜", "en": "Emotion Score"},
    "col_cognition": {"ko": "ì‚¬ê³  ê³„ìˆ˜", "en": "Cognition Score"},
    "col_expression": {"ko": "í‘œí˜„ ê³„ìˆ˜", "en": "Expression Score"},
    "col_value": {"ko": "ê°€ì¹˜ ê³„ìˆ˜", "en": "Value Score"},
    "col_bias": {"ko": "í¸í–¥ ê³„ìˆ˜", "en": "Bias Score"},
    "col_role": {"ko": "í•µì‹¬ ì—­í• ", "en": "Core Role"},
}

# --- Page Config ---
st.set_page_config(
    page_title=TEXTS["page_title"]["en"],
    page_icon="ğŸ¤–",
    layout="wide"
)

# --- Initialize Session State ---
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = {}
if 'lang' not in st.session_state:
    st.session_state.lang = 'ko'

# --- Sidebar for Settings ---
with st.sidebar:
    st.header(TEXTS["sidebar_header"][st.session_state.lang])
    
    lang_choice = st.selectbox(
        label=f'{TEXTS["language_selector"]["en"]} / {TEXTS["language_selector"]["ko"]}',
        options=['í•œêµ­ì–´', 'English'],
        index=0 if st.session_state.lang == 'ko' else 1,
        key='lang_selector'
    )
    st.session_state.lang = 'ko' if lang_choice == 'í•œêµ­ì–´' else 'en'
    lang = st.session_state.lang

# --- API Key Configuration (Runs only once) ---
api_configured = False
try:
    # --- THIS IS THE CORRECTED LINE ---
    genai.configure(api_key=st.secrets["GOOGLE_AI_API_KEY"])
    api_configured = True
except (KeyError, AttributeError):
    st.error(TEXTS["api_key_error_title"][lang])
    st.warning(TEXTS["api_key_error_body"][lang])
    api_configured = False


# --- Main UI ---
st.title(TEXTS["main_title"][lang])
st.markdown(TEXTS["main_description"][lang])

# --- Prompts (Full prompts included) ---
PROMPT_TEAM_PROFILE = """
ë‹¹ì‹ ì€ ì¡°ì§ ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì±„íŒ… ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ, 'ë¯¸ëŸ¬ì˜¤ì•Œì§€ íŒ€ ë¶„ì„ ì‚¬ë¡€' ë¬¸ì„œì˜ 'ì •ì²´ì„± ê³„ìˆ˜ ë§µ'ê³¼ ê°™ì´ ê° íŒ€ì›ì˜ íŠ¹ì„±ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

**ë¶„ì„ ê·œì¹™:**
1.  **ì°¸ì—¬ì ì‹ë³„:** ì±„íŒ… ê¸°ë¡ì— ë“±ì¥í•˜ëŠ” ëª¨ë“  ì£¼ìš” ì°¸ì—¬ìë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.
2.  **5ëŒ€ ê³„ìˆ˜ ë¶„ì„:** ê° ì°¸ì—¬ìì— ëŒ€í•´ ë‹¤ìŒ 5ê°€ì§€ ê³„ìˆ˜ë¥¼ 1-10ì  ì²™ë„ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
    * **ê°ì •(Emotion):** ê°ì • í‘œí˜„ì˜ ë¹ˆë„ì™€ ê°•ë„.
    * **ì‚¬ê³ (Cognition):** ë…¼ë¦¬ì , ë¶„ì„ì , ì „ëµì  ë°œì–¸ì˜ ë¹ˆë„.
    * **í‘œí˜„(Expression):** ì˜ê²¬, ìƒíƒœ, ì•„ì´ë””ì–´ í‘œí˜„ì˜ ì ê·¹ì„±.
    * **ê°€ì¹˜(Value):** íŒ€ì˜ ëª©í‘œ, ë¹„ì „, í•µì‹¬ ê°€ì¹˜ì— ëŒ€í•œ ì–¸ê¸‰.
    * **í¸í–¥(Bias):** íŠ¹ì • ì£¼ì œë‚˜ ë°©ì‹ì— ëŒ€í•œ ì„ í˜¸/íšŒí”¼ ê²½í–¥.
3.  **í•µì‹¬ ì—­í•  ë¶€ì—¬:** ê° ì°¸ì—¬ìì˜ ê³„ìˆ˜ë¥¼ ì¢…í•©í•˜ì—¬ 'The Driver', 'The Coordinator' ë“± ê°€ì¥ ì í•©í•œ í•µì‹¬ ì—­í• ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.
4.  **JSON í˜•ì‹ ì¶œë ¥:** ì•„ë˜ì™€ ê°™ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
    ```json
    [
      {
        "name": "ì°¸ì—¬ì ì´ë¦„",
        "emotion_score": 5,
        "cognition_score": 9,
        "expression_score": 6,
        "value_score": 9,
        "bias_score": 7,
        "core_role": "The Driver (ì „ëµ ì¤‘ì‹¬)"
      }
    ]
    ```

**[ì…ë ¥ ë°ì´í„°: ì±„íŒ… ê¸°ë¡]**
---
{chat_log}
---
"""

PROMPT_FATIGUE_TIMELINE = """
ë‹¹ì‹ ì€ ì¡°ì§ í–‰ë™ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì±„íŒ… ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬, ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ê° íŒ€ì›ì˜ 'í”¼ë¡œë„(Fatigue)' ë³€í™”ë¥¼ ì¶”ì •í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë‚ ì§œë³„ JSON ë°ì´í„°ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

**ë¶„ì„ ê·œì¹™:**
1.  **í”¼ë¡œë„ ì •ì˜:** í”¼ë¡œë„ëŠ” ì—…ë¬´ ë¶€ë‹´, ìŠ¤íŠ¸ë ˆìŠ¤, ë¶€ì •ì  ê°ì • í‘œí˜„, ë°˜ì‘ ì†ë„ ì €í•˜ ë“±ì„ ì¢…í•©í•˜ì—¬ 1-10ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. (1: ë§¤ìš° ë‚®ìŒ, 10: ë§¤ìš° ë†’ìŒ/ì†Œì§„ ì„ë°•)
2.  **ë‚ ì§œë³„ ë¶„ì„:** ì±„íŒ… ê¸°ë¡ì— ë‚˜íƒ€ë‚œ ë‚ ì§œë³„ë¡œ ê° ì°¸ì—¬ìì˜ í”¼ë¡œë„ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤. íŠ¹ì • ë‚ ì§œì— ë°œì–¸ì´ ì—†ìœ¼ë©´ ì´ì „ ìƒíƒœë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ì£¼ë³€ ìƒí™©ì— ë”°ë¼ ì¶”ì •í•©ë‹ˆë‹¤.
3.  **JSON í˜•ì‹ ì¶œë ¥:** ì•„ë˜ì™€ ê°™ì€ ë‚ ì§œ-ì‚¬ìš©ì-ì ìˆ˜ êµ¬ì¡°ì˜ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
    ```json
    {
      "YYYY-MM-DD": {
        "ì°¸ì—¬ì1": 3,
        "ì°¸ì—¬ì2": 5
      },
      "YYYY-MM-DD": {
        "ì°¸ì—¬ì1": 4,
        "ì°¸ì—¬ì2": 6
      }
    }
    ```

**[ì…ë ¥ ë°ì´í„°: ì±„íŒ… ê¸°ë¡]**
---
{chat_log}
---
"""

PROMPT_CONFLICT_NETWORK = """
ë‹¹ì‹ ì€ ê´€ê³„ ë™ì—­í•™ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì±„íŒ… ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬, íŒ€ì› ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ 'ê°ˆë“± ë„¤íŠ¸ì›Œí¬'ë¡œ ëª¨ë¸ë§í•˜ê³ , ê·¸ êµ¬ì¡°ë¥¼ ë…¸ë“œ(node)ì™€ ì—£ì§€(edge) í˜•íƒœì˜ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

**ë¶„ì„ ê·œì¹™:**
1.  **ë…¸ë“œ(Nodes):** ì±„íŒ…ì— ì°¸ì—¬í•œ ëª¨ë“  íŒ€ì›ì„ ë…¸ë“œë¡œ ì •ì˜í•©ë‹ˆë‹¤.
2.  **ì—£ì§€(Edges):** ë‘ íŒ€ì› ê°„ì˜ ì£¼ìš” ìƒí˜¸ì‘ìš©ì„ ì—£ì§€ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
3.  **ê´€ê³„ ìœ í˜•(Relationship Type):** ê° ì—£ì§€ì— ëŒ€í•´ ê´€ê³„ë¥¼ ë‹¤ìŒ 4ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    * `high_risk`: ì˜ê²¬ ì¶©ëŒ, ë¹„ë‚œ, ë¬´ì‹œ ë“± ëª…ë°±í•œ ê°ˆë“±.
    * `medium_risk`: ì¦ì€ ì˜ê²¬ ë¶ˆì¼ì¹˜, ê¸´ì¥ê° ìˆëŠ” ëŒ€í™”.
    * `potential_risk`: ì ì¬ì  ì˜¤í•´ë‚˜ ì˜ê²¬ ì°¨ì´ê°€ ìˆëŠ” ê´€ê³„.
    * `stable`: ì§€ì§€, ë™ì˜, í˜‘ë ¥ ë“± ì•ˆì •ì ì¸ ê´€ê³„.
4.  **JSON í˜•ì‹ ì¶œë ¥:** ì•„ë˜ì™€ ê°™ì€ ë…¸ë“œì™€ ì—£ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ JSON ê°ì²´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
    ```json
    {
      "nodes": [
        {"id": "ì°¸ì—¬ì1", "label": "ì°¸ì—¬ì1"},
        {"id": "ì°¸ì—¬ì2", "label": "ì°¸ì—¬ì2"}
      ],
      "edges": [
        {"from": "ì°¸ì—¬ì1", "to": "ì°¸ì—¬ì2", "type": "high_risk"},
        {"from": "ì°¸ì—¬ì1", "to": "ì°¸ì—¬ì3", "type": "stable"}
      ]
    }
    ```

**[ì…ë ¥ ë°ì´í„°: ì±„íŒ… ê¸°ë¡]**
---
{chat_log}
---
"""

# --- Functions ---
def parse_kakao_talk(file_content):
    pattern = re.compile(r"--------------- (\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼) ")
    chat_lines = file_content.split('\n')
    data, current_date = [], None
    for line in chat_lines:
        date_match = pattern.match(line)
        if date_match:
            current_date_str = date_match.group(1)
            current_date = datetime.strptime(current_date_str, "%Yë…„ %mì›” %dì¼").date()
        elif line.startswith('[') and current_date:
            try:
                parts = line.split('] ', 2)
                if len(parts) == 3:
                    data.append({"date": current_date, "speaker": parts[0][1:], "message": parts[2]})
            except (IndexError, ValueError): continue
    return pd.DataFrame(data) if data else None

def call_gemini_api(prompt, chat_log):
    model = genai.GenerativeModel('gemini-pro')
    full_prompt = prompt.format(chat_log=chat_log)
    try:
        response = model.generate_content(full_prompt)
        cleaned_text = response.text.strip().replace("```json", "").replace("```", "")
        return json.loads(cleaned_text)
    except (json.JSONDecodeError, AttributeError, ValueError) as e:
        st.error(f"{TEXTS['api_parse_error'][lang]}: {response.text[:500]}")
        return None
    except Exception as e:
        st.error(f"{TEXTS['api_call_error'][lang]}: {e}")
        return None

def draw_network_graph(network_data):
    if not network_data or 'nodes' not in network_data or 'edges' not in network_data:
        st.warning(TEXTS["network_warning"][lang])
        return
    net = Network(height="600px", width="100%", bgcolor="#222222", font_color="white", notebook=True, directed=False)
    color_map = {"high_risk": "#FF4136", "medium_risk": "#FF851B", "potential_risk": "#FFDC00", "stable": "#DDDDDD"}
    for node in network_data['nodes']: net.add_node(node['id'], label=node['label'], size=25)
    for edge in network_data['edges']:
        edge_type = edge.get('type', 'stable')
        net.add_edge(edge['from'], edge['to'], color=color_map.get(edge_type, "#DDDDDD"), width=4 if edge_type == 'high_risk' else 2)
    try:
        net.save_graph("network_graph.html")
        with open("network_graph.html", 'r', encoding='utf-8') as f: html_content = f.read()
        components.html(html_content, height=620)
    except Exception as e: st.error(f"{TEXTS['network_error'][lang]}: {e}")

# --- Main App Logic ---
if api_configured:
    st.header(TEXTS["upload_header"][lang])
    st.info(TEXTS["upload_info"][lang])

    uploaded_file = st.file_uploader(TEXTS["file_uploader_label"][lang], type="txt", key="file_uploader")

    if uploaded_file is not None:
        try:
            file_content = uploaded_file.getvalue().decode("utf-8")
            chat_df = parse_kakao_talk(file_content)

            if chat_df is not None:
                st.success(TEXTS["parsing_success"][lang].format(count=len(chat_df)))
                
                if st.button(TEXTS["analysis_button"][lang], key="start_analysis"):
                    chat_log_for_api = "\n".join(chat_df.apply(lambda row: f"[{row['speaker']}] {row['message']}", axis=1))
                    
                    with st.spinner(TEXTS["spinner_profile"][lang]):
                        st.session_state.analysis_result['profile'] = call_gemini_api(PROMPT_TEAM_PROFILE, chat_log_for_api)
                    with st.spinner(TEXTS["spinner_timeline"][lang]):
                        st.session_state.analysis_result['timeline'] = call_gemini_api(PROMPT_FATIGUE_TIMELINE, chat_log_for_api)
                    with st.spinner(TEXTS["spinner_network"][lang]):
                        st.session_state.analysis_result['network'] = call_gemini_api(PROMPT_CONFLICT_NETWORK, chat_log_for_api)
                    
                    st.success(TEXTS["analysis_complete"][lang])
            else:
                st.error(TEXTS["parsing_error"][lang])
        except Exception as e:
            st.error(f"{TEXTS['file_process_error'][lang]}: {e}")

    # --- Display Results in Tabs ---
    if st.session_state.analysis_result:
        st.header(TEXTS["results_header"][lang])
        
        tab_titles = [TEXTS["tab_profile"][lang], TEXTS["tab_fatigue"][lang], TEXTS["tab_network"][lang]]
        tab1, tab2, tab3 = st.tabs(tab_titles)

        with tab1:
            st.subheader(TEXTS["profile_subheader"][lang])
            st.info(TEXTS["profile_info"][lang])
            profile_data = st.session_state.analysis_result.get('profile')
            if profile_data:
                try:
                    profile_df = pd.DataFrame(profile_data)
                    profile_df.rename(columns={
                        "name": TEXTS['col_name'][lang],
                        "emotion_score": TEXTS['col_emotion'][lang],
                        "cognition_score": TEXTS['col_cognition'][lang],
                        "expression_score": TEXTS['col_expression'][lang],
                        "value_score": TEXTS['col_value'][lang],
                        "bias_score": TEXTS['col_bias'][lang],
                        "core_role": TEXTS['col_role'][lang],
                    }, inplace=True)
                    st.dataframe(profile_df, use_container_width=True)
                except Exception as e:
                    st.error(f"{TEXTS['profile_error'][lang]}: {e}")
                    st.json(profile_data)
            else:
                st.warning(TEXTS["profile_warning"][lang])

        with tab2:
            st.subheader(TEXTS["fatigue_subheader"][lang])
            st.info(TEXTS["fatigue_info"][lang])
            timeline__data = st.session_state.analysis_result.get('timeline')
            if timeline_data:
                try:
                    timeline_df = pd.DataFrame.from_dict(timeline_data, orient='index')
                    timeline_df.index = pd.to_datetime(timeline_df.index)
                    timeline_df = timeline_df.sort_index()
                    st.line_chart(timeline_df)
                except Exception as e:
                    st.error(f"{TEXTS['fatigue_error'][lang]}: {e}")
                    st.json(timeline_data)
            else:
                st.warning(TEXTS["fatigue_warning"][lang])

        with tab3:
            st.subheader(TEXTS["network_subheader"][lang])
            st.info(TEXTS["network_info"][lang])
            network_data = st.session_state.analysis_result.get('network')
            if network_data:
                draw_network_graph(network_data)
            else:
                st.warning(TEXTS["network_warning"][lang])
