import streamlit as st
import google.generativeai as genai
import analyzer
import pandas as pd

TEXTS = {
    "page_title": {"ko": "MirrorOrg MVP", "en": "MirrorOrg MVP"},
    "main_title": {"ko": "ğŸª MirrorOrg MVP: ì¢…í•© íŒ€ ë¶„ì„", "en": "ğŸª MirrorOrg MVP: Comprehensive Team Analysis"},
    "main_description": {
        "ko": "'ë¯¸ëŸ¬ì˜¤ì•Œì§€ íŒ€ ë¶„ì„ ì‚¬ë¡€'ì— ê¸°ë°˜í•œ ë‹¤ì°¨ì› í˜‘ì—… ì§„ë‹¨ ë„êµ¬ì…ë‹ˆë‹¤.\n**íŒ€ ì±„íŒ… ê¸°ë¡(ì¹´ì¹´ì˜¤í†¡, ìŠ¬ë™ ë“±)**ì„ ì—…ë¡œë“œí•˜ì—¬ ì±•í„°ë³„ ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "en": "A multi-dimensional collaboration diagnostic tool based on the 'MirrorOrg Team Analysis Case Study'.\nUpload your **team chat history (e.g., KakaoTalk, Slack)** and run each analysis chapter independently."
    },
    "sidebar_header": {"ko": "ì„¤ì •", "en": "Settings"},
    "language_selector": {"ko": "ì–¸ì–´", "en": "Language"},
    "api_key_error_title": {"ko": "API í‚¤ ì„¤ì • ì˜¤ë¥˜", "en": "API Key Configuration Error"},
    "api_key_error_body": {
        "ko": "ì•± ê´€ë¦¬ìê°€ ì„¤ì •í•œ API í‚¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. Streamlit Cloudì˜ 'Secrets' ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "en": "There is an issue with the API key configured by the app administrator. Please check the 'Secrets' settings on Streamlit Cloud."
    },
    "upload_header": {"ko": "1. ì±„íŒ… ê¸°ë¡ ì—…ë¡œë“œ", "en": "1. Upload Chat History"},
    "upload_info": {
        "ko": "íŒ€ ì±„íŒ… ê¸°ë¡ì„ í…ìŠ¤íŠ¸(.txt) íŒŒì¼ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”. ë‹¤ì–‘í•œ í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.",
        "en": "Upload your team chat history as a text (.txt) file. Various formats are supported."
    },
    "file_uploader_label": {"ko": "ë¶„ì„í•  .txt íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", "en": "Choose a .txt file to analyze."},
    "chapter_header": {
        "ko": "2. ì±•í„°ë³„ ë¶„ì„ ì‹¤í–‰", "en": "2. Run Each Analysis Chapter"
    },
    "chapter1_btn": {"ko": "ì±•í„° 1: ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±", "en": "Chapter 1: Generate Comprehensive Report"},
    "chapter2_btn": {"ko": "ì±•í„° 2: í”¼ë¡œë„ ê³¡ì„  ë¶„ì„", "en": "Chapter 2: Analyze Fatigue Trajectory"},
    "chapter3_btn": {"ko": "ì±•í„° 3: ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë¶„ì„", "en": "Chapter 3: Analyze Relationship Network"},
    "spinner_report": {"ko": "ë³´ê³ ì„œë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...", "en": "Generating report..."},
    "spinner_fatigue": {"ko": "í”¼ë¡œë„ ê³¡ì„  ë¶„ì„ ì¤‘...", "en": "Analyzing fatigue trajectory..."},
    "spinner_network": {"ko": "ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì¤‘...", "en": "Analyzing relationship network..."},
    "analysis_complete": {"ko": "âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!", "en": "âœ… Analysis complete!"},
    "file_process_error": {"ko": "íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤", "en": "An unknown error occurred while processing the file"},
    "results_header": {"ko": "3. ë¶„ì„ ê²°ê³¼", "en": "3. Results"},
    "fatigue_title": {"ko": "3.1 í”¼ë¡œë„ ë³€í™” (Fatigue Trajectory)", "en": "3.1 Fatigue Trajectory"},
    "network_title": {"ko": "3.2 ê´€ê³„ ë„¤íŠ¸ì›Œí¬ (Relationship Network)", "en": "3.2 Relationship Network"},
    "no_fatigue_data": {"ko": "í”¼ë¡œë„ ê³¡ì„  ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "en": "Fatigue trajectory data could not be generated."},
    "no_network_data": {"ko": "ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "en": "Network data could not be generated."}
}

# 1. Page config
st.set_page_config(page_title=TEXTS["page_title"]["en"], page_icon="ğŸ¤–", layout="wide")
if 'lang' not in st.session_state:
    st.session_state.lang = 'ko'

# 2. Sidebar (Language Switch)
with st.sidebar:
    st.header(TEXTS["sidebar_header"][st.session_state.lang])
    lang_choice = st.selectbox(
        label=f'{TEXTS["language_selector"]["en"]} / {TEXTS["language_selector"]["ko"]}',
        options=['í•œêµ­ì–´', 'English'],
        index=0 if st.session_state.lang == 'ko' else 1
    )
    st.session_state.lang = 'ko' if lang_choice == 'í•œêµ­ì–´' else 'en'
lang = st.session_state.lang

# 3. API Key Config
api_configured = False
try:
    genai.configure(api_key=st.secrets["GOOGLE_AI_API_KEY"])
    api_configured = True
except (KeyError, AttributeError):
    st.error(TEXTS["api_key_error_title"][lang])
    st.warning(TEXTS["api_key_error_body"][lang])

# 4. Main UI
st.title(TEXTS["main_title"][lang])
st.markdown(TEXTS["main_description"][lang])

if api_configured:
    st.header(TEXTS["upload_header"][lang])
    st.info(TEXTS["upload_info"][lang])
    uploaded_file = st.file_uploader(TEXTS["file_uploader_label"][lang], type="txt")

    if uploaded_file:
        try:
            if 'uploaded_file_id' not in st.session_state or uploaded_file.file_id != st.session_state.uploaded_file_id:
                # ìƒˆ íŒŒì¼ì´ë©´ ëª¨ë“  ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”
                st.session_state.report = None
                st.session_state.fatigue_data = None
                st.session_state.network_data = None
                st.session_state.uploaded_file_id = uploaded_file.file_id

            file_content = uploaded_file.getvalue().decode("utf-8")
            st.success(f"'{uploaded_file.name}' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

            st.header(TEXTS["chapter_header"][lang])
            c1, c2, c3 = st.columns(3)

            # ì±•í„° 1: ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ
            with c1:
                if st.button(TEXTS["chapter1_btn"][lang], use_container_width=True):
                    with st.spinner(TEXTS["spinner_report"][lang]):
                        st.session_state.report = analyzer.generate_report(file_content, lang=lang)
                    st.toast(TEXTS["analysis_complete"][lang], icon="âœ…")

            # ì±•í„° 2: í”¼ë¡œë„ ê³¡ì„ 
            with c2:
                if st.button(TEXTS["chapter2_btn"][lang], use_container_width=True):
                    with st.spinner(TEXTS["spinner_fatigue"][lang]):
                        st.session_state.fatigue_data = analyzer.analyze_fatigue_json(file_content, lang=lang)
                    st.toast(TEXTS["analysis_complete"][lang], icon="âœ…")

            # ì±•í„° 3: ê´€ê³„ ë„¤íŠ¸ì›Œí¬
            with c3:
                if st.button(TEXTS["chapter3_btn"][lang], use_container_width=True):
                    with st.spinner(TEXTS["spinner_network"][lang]):
                        st.session_state.network_data = analyzer.analyze_network_json(file_content, lang=lang)
                    st.toast(TEXTS["analysis_complete"][lang], icon="âœ…")

            # ê²°ê³¼ ì¶œë ¥ êµ¬ê°„
            st.header(TEXTS["results_header"][lang])

            # --- ì¢…í•© ë³´ê³ ì„œ ---
            if st.session_state.get('report'):
                st.markdown(st.session_state.report, unsafe_allow_html=True)
                st.divider()

            # --- í”¼ë¡œë„ ê³¡ì„  ---
            st.subheader(TEXTS["fatigue_title"][lang])
            fatigue_data = st.session_state.get('fatigue_data')
            if fatigue_data and isinstance(fatigue_data, list):
                try:
                    lines = []
                    for item in fatigue_data:
                        for d in item["fatigue_timeline"]:
                            lines.append({"name": item["name"], "date": d["date"], "score": d["score"]})
                    df = pd.DataFrame(lines)
                    chart_data = df.pivot(index="date", columns="name", values="score")
                    st.line_chart(chart_data)
                except Exception as e:
                    st.error(f"{TEXTS['no_fatigue_data'][lang]}: {e}")
            elif fatigue_data and "raw_response" in fatigue_data:
                st.warning("LLM ì›ë³¸ ì‘ë‹µ(raw):")
                st.code(fatigue_data["raw_response"])
                st.info(TEXTS["no_fatigue_data"][lang])
            else:
                st.info(TEXTS["no_fatigue_data"][lang])

            # --- ë„¤íŠ¸ì›Œí¬ ---
            st.subheader(TEXTS["network_title"][lang])
            network_data = st.session_state.get('network_data')
            if network_data and isinstance(network_data, list):
                try:
                    import networkx as nx
                    import matplotlib.pyplot as plt
                    G = nx.Graph()
                    for link in network_data:
                        G.add_edge(link["source"], link["target"], weight=link["strength"])
                    fig, ax = plt.subplots()
                    pos = nx.spring_layout(G)
                    nx.draw(G, pos, with_labels=True, ax=ax, node_color='lightblue', edge_color='gray')
                    st.pyplot(fig)
                except Exception as e:
                    st.error(f"{TEXTS['no_network_data'][lang]}: {e}")
            elif network_data and "raw_response" in network_data:
                st.warning("LLM ì›ë³¸ ì‘ë‹µ(raw):")
                st.code(network_data["raw_response"])
                st.info(TEXTS["no_network_data"][lang])
            else:
                st.info(TEXTS["no_network_data"][lang])

        except Exception as e:
            st.error(f"{TEXTS['file_process_error'][lang]}: {e}")
else:
    st.warning("API ë¯¸ì„¤ì •: ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
