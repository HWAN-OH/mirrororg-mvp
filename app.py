import streamlit as st
import openai
import json
import re
from collections import Counter

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    client = openai.OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception as e:
    st.error(f"OpenAI API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    client = None

# âœ… MirrorMind ë°©ì‹ í”„ë¡¬í”„íŠ¸
PROMPT_NETWORK_JSON = '''
# MirrorMind ë¶„ì„ í”„ë¡œí† ì½œ

ë‹¹ì‹ ì€ ê³ ê¸‰ ì‚¬íšŒì‹¬ë¦¬ ëª¨ë¸ ê¸°ë°˜ì˜ AI ë¶„ì„ê°€ì´ë©°, ë‹¤ìŒ ëŒ€í™” í…ìŠ¤íŠ¸ë¥¼ ì½ê³  ì¸ë¬¼ ê°„ì˜ **ì§€ì§€(support)** ë˜ëŠ” **ê°ˆë“±(conflict)** ê´€ê³„ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤. ì´ ê´€ê³„ëŠ” ë‹¨ìˆœí•œ ì–¸ê¸‰ì´ ì•„ë‹ˆë¼ **ì˜ë„, ê°ì •, ë¬¸ë§¥, ë°˜ì‘ì˜ ìŠ¤íƒ€ì¼**ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê²°ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

## ë¶„ì„ ê·œì¹™
- ê° ê´€ê³„ëŠ” ë‹¤ìŒ 4ê°œ í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
```json
{ "source": "ë§í•œ ì‚¬ëŒ", "target": "ìƒëŒ€ë°©", "strength": 0.1~1.0, "type": "support" ë˜ëŠ” "conflict" }
```
- ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ë¶ˆí•„ìš”í•œ ì„¤ëª…ì„ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

## ì¶œë ¥ ì˜ˆì‹œ
```json
[
  { "source": "í˜„ì§„", "target": "ìœ ë¯¸", "strength": 0.8, "type": "conflict" },
  { "source": "ì—ë¦¬ì¹´", "target": "í˜„ì§„", "strength": 0.6, "type": "support" }
]
```

## ë¶„ì„ ëŒ€ìƒ ëŒ€í™”
{chat_log}
'''

def call_openai_api(prompt: str, model="gpt-3.5-turbo", max_tokens=2048) -> str:
    if not client:
        return json.dumps({"error": "OpenAI client is not initialized."})
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens,
            temperature=0.2,
        )
        return response.choices[0].message.content
    except Exception as e:
        return json.dumps({"error": f"API call failed: {e}"})

def analyze_network_json(chat_log: str, lang: str = 'ko'):
    prompt = PROMPT_NETWORK_JSON.format(chat_log=chat_log)
    result_text = call_openai_api(prompt)

    try:
        match = re.search(r"```json\s*([\s\S]*?)\s*```", result_text)
        if match:
            json_text = match.group(1)
        else:
            json_text = result_text
        parsed = json.loads(json_text)
        return {
            "data": parsed,
            "raw_response": result_text,
            "prompt": prompt
        }
    except (json.JSONDecodeError, TypeError) as e:
        return {
            "error": f"Failed to decode JSON from LLM response: {e}",
            "raw_response": result_text,
            "prompt": prompt
        }

# ------------------------------
# STREAMLIT UI STARTS HERE
# ------------------------------

st.set_page_config(page_title="MirrorOrg ì¡°ì§ ì§„ë‹¨ ìš”ì•½ / Organizational Summary", layout="wide")
st.title("ğŸª MirrorOrg ì¡°ì§ ì§„ë‹¨ ìš”ì•½ / Organizational Summary")

with st.sidebar:
    st.markdown("## ğŸ“ ë¶„ì„ ëª©ì  / Purpose")
    st.markdown("""
    ì´ ë„êµ¬ëŠ” MirrorMind ë°©ì‹ì— ë”°ë¼ êµ¬ì„±ì› ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ë¶„ì„í•˜ì—¬ **ì„±í–¥ì˜ ì°¨ì´**ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.  
    **ì´ ë¶„ì„ì€ ìš°ì—´ í‰ê°€ë‚˜ ì¸ì‚¬ ëª©ì ì´ ì•„ë‹ˆë©°**, ì‹¬ì¸µì  ì´í•´ì™€ ì¡°ì§ ë‚´ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê°œì„ ì„ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.
    
    ---
    This tool visualizes interpersonal dynamics using the MirrorMind methodology, highlighting **differences in tendencies**,  
    **not for evaluation or HR purposes**, but to enhance understanding and communication within the organization.
    """)

    st.markdown("## âš–ï¸ ì €ì‘ê¶Œ / Copyright")
    st.markdown("""
    Â© 2025 Sunghwan Oh. All rights reserved.  
    Unauthorized reproduction or redistribution is prohibited.
    """)

    st.markdown("## ğŸŒ ì–¸ì–´ ì „í™˜ / Language")
    lang = st.radio("Select Language", options=["í•œêµ­ì–´", "English"], index=0, key="language_radio")

uploaded_file = st.file_uploader("ë¶„ì„í•  .txt íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (Upload a .txt file for analysis)", type="txt")
if not uploaded_file:
    st.stop()

file_content = uploaded_file.getvalue().decode("utf-8")
st.success(f"'{uploaded_file.name}' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤ / Successfully uploaded")

def get_short_content(content, max_lines=2000):
    lines = content.splitlines()
    return "\n".join(lines[-max_lines:]) if len(lines) > max_lines else content

def generate_text_summary(network_data):
    if not isinstance(network_data, list):
        return "âš ï¸ ì˜¤ë¥˜: ë¶„ì„ ê²°ê³¼ê°€ ì˜¬ë°”ë¥¸ JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. / Invalid format returned."
    supports = [x for x in network_data if x.get("type") == "support"]
    conflicts = [x for x in network_data if x.get("type") == "conflict"]
    all_names = [x["source"] for x in network_data] + [x["target"] for x in network_data]
    name_counts = Counter(all_names)
    support_to = Counter([x["target"] for x in supports])
    conflict_to = Counter([x["target"] for x in conflicts])
    leader = support_to.most_common(1)[0][0] if support_to else "ì—†ìŒ / None"
    top_conflict = conflict_to.most_common(1)[0][0] if conflict_to else "ì—†ìŒ / None"
    top_people = [name for name, _ in name_counts.most_common(3)]

    summary = f"""
### ğŸ§¾ ì¡°ì§ ì§„ë‹¨ ìš”ì•½ / Organizational Diagnosis Summary (MirrorMind ê¸°ë°˜)

- ğŸ“Œ **ë¦¬ë” / Leader**: `{leader}`
- âš ï¸ **ê°ˆë“± ì§‘ì¤‘ ì¸ë¬¼ / Conflict-prone figure**: `{top_conflict}`
- ğŸ‘¥ **í•µì‹¬ ì¸ë¬¼ë“¤ / Key Figures**: {', '.join(top_people)}

---

### ğŸ” ì¢…í•© ì œì–¸ / Insights & Suggestions

- ë¦¬ë”ëŠ” ì¤‘ì¬ì ì—­í• ì„ ê°•í™”í•´ì•¼ í•©ë‹ˆë‹¤.  
  â†’ The leader should strengthen their mediator role.

- ê°ˆë“±ì´ ì§‘ì¤‘ëœ ì¸ë¬¼ì€ í”¼ë“œë°± ë°©ì‹ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.  
  â†’ Conflict-heavy personas need feedback and role recalibration.

- ì§€ì§€ ë„¤íŠ¸ì›Œí¬ í™•ì¥ì´ ì¡°ì§ ì•ˆì •ì„±ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.  
  â†’ Expanding the support network enhances team stability.
    """
    return summary

if st.button("ì§„ë‹¨ ì‹¤í–‰ (Run Diagnosis)", use_container_width=True):
    with st.spinner("ë¶„ì„ ì¤‘... / Analyzing..."):
        short_content = get_short_content(file_content)
        result = analyze_network_json(short_content)

    st.subheader("ğŸ“„ GPT ì›ë³¸ ì‘ë‹µ / Raw GPT Response")
    st.code(result.get("raw_response", "ì‘ë‹µ ì—†ìŒ / No response"))

    st.subheader("ğŸ§ª ì‚¬ìš©ëœ GPT í”„ë¡¬í”„íŠ¸ / Prompt")
    st.code(result.get("prompt", "í”„ë¡¬í”„íŠ¸ ì—†ìŒ / No prompt"))

    if "data" in result:
        if not isinstance(result["data"], list):
            st.error("âŒ ê²°ê³¼ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜: ì˜ˆìƒí•œ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜ / Invalid format")
        else:
            st.markdown(generate_text_summary(result["data"]))
    elif "error" in result:
        st.error("âŒ ì§„ë‹¨ ì‹¤íŒ¨ / Diagnosis Failed: JSON ë¶„ì„ ì‹¤íŒ¨")

